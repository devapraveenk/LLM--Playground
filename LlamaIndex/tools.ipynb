{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def addition(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "addition_tool = FunctionTool.from_defaults(fn=addition)\n",
    "mystry_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-4o-mini')\n",
    "response = llm.predict_and_call(\n",
    "    [addition_tool, mystry_tool],\n",
    "    \"Tell me the output of the mystry function on 2 and 9\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "#loading\n",
    "documents = SimpleDirectoryReader(input_files=['../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf']).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf\n",
      "file_path: ../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 682557\n",
      "creation_date: 2024-11-05\n",
      "last_modified_date: 2024-10-30\n",
      "\n",
      "1  The 7th Sense For Data-Driven Decision Mastery Raja Brundha A  Assistant Professor Department of Artificial  Intelligence and Data Science,  Sri Sai Ram Engineering College, Chennai, Tamil Nadu, India. rajabrundha.ai@sairam.edu.in   Abubacker S  Student Department of Artificial  Intelligence and Data Science, Sri Sai Ram Engineering College, Chennai, Tamil Nadu, India. nav.abubacker@gmail.com    Deva Praveen K  Student Department of Artificial  Intelligence and Data Science,  Sri Sai Ram Engineering College, Chennai, Tamil Nadu, India. devapraveen20@gmail.com     Abstract— Our project automates the manual data analytics pipeline, transforming it into a seamless, AI-powered process designed to revolutionize decision-making and drive strategic innovation. By connecting to a client’s database, it automates data preprocessing, cleaning, and imputation, ensuring accurate data types through sophisticated feature-template similarity calculations. The system generates a comprehensive abstracted text file, detailing metadata, feature descriptions, missing values, and statistical summaries, alongside advanced analyses such as RFM, customer behavior clustering, and churn prediction. Leveraging cutting-edge generative AI with retrieval-augmented generation (RAG) and few-shot prompting, the project converts text files into embeddings, indexed in a vector database for insightful, similarity-based content retrieval. This allows decision-makers to quickly access vital insights, interpret complex data, and make informed decisions, ultimately driving business success. By providing a fast, accurate, and thorough analysis, our project empowers decision-makers to stay ahead of trends, transforming how data is used in strategic planning, and setting a new global standard in the competitive business world. Keywords—Retail Data Analytics, Retrieval augmented generation kRAG), Large Language Models (LLMs), Natural Language Processing, Few-Shot Learning, Business Intelligence, Analytics Agent, Statistical Patterns, Data-Driven Decision Marking, Retail trends , Business growth. I. INTRODUCTION In today’s data-driven world, businesses are inundated with vast amounts of data that hold the potential to unlock significant insights. However, the manual process of analyzing this data is often time-consuming, error-prone, and inefficient. As companies strive to remain competitive, the need for an automated, reliable, and intelligent data analytics system has never been more critical.  Traditional data analysis methods often require extensive human  intervention, from data cleaning and preprocessing to complex statistical analysis and visualization. These steps, while essential, can lead to inconsistencies and delays, impeding timely decision-making. The limitations of manual processes underscore the necessity for a more streamlined, automated solution that can handle large datasets with precision and speed.  Our project addresses these challenges by developing an advanced automated data analytics pipeline. This system is designed to seamlessly connect to client databases, fetch relevant data, and perform comprehensive preprocessing tasks, including cleaning, imputation, and ensuring correct data types. By automating these foundational steps, the system significantly reduces the potential for human error and accelerates the overall analysis process.  Beyond preprocessing, the system also generates detailed abstracts of the data, encompassing metadata, feature descriptions, and statistical summaries. These abstracts include rigorous statistical tests to identify normal distributions, outliers, and influential points. By providing this level of detail, the system ensures that decision-makers have access to a complete and accurate picture of the data at their disposal.  One of the standout features of our project is the integration of generative AI techniques, specifically retrieval-augmented generation (RAG) and few-shot prompting. These technologies enable the system to convert abstracted data files into embeddings, which are then indexed in a vector database. This allows for efficient, similarity-based content retrieval, facilitating more insightful and actionable analysis.  In addition to its analytical capabilities, the system incorporates a question-answering chatbox that interacts with decision-makers, helping to clarify requirements and refine analysis outputs. This interactive component ensures that the analysis is not only thorough but also aligned with the specific needs and goals of the business, enhancing its relevance and utility.  By automating and enhancing the data analysis process, our project empowers decision-makers with faster, more accurate, and more comprehensive insights. This not only accelerates strategic planning and implementation but also sets a new standard for how businesses leverage data in a rapidly evolving and competitive global marketplace.Related Works  II. LITERATURE SURVEY  The evolving landscape of retail, fashion, and data analysis has seen significant advances in machine learning, large language models (LLMs), and data-driven decision-making. This literature survey examines eight key papers, each contributing uniquely to the field, ranging from retail Bastin A  Student Department of Artificial  Intelligence and Data Science, Sri Sai Ram Engineering College, Chennai, Tamil Nadu, India.\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_content(metadata_mode='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic Query engine\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 7th Sense is a project that employs a multi-step approach to automate the data analysis process, starting from connecting to the client's database, performing automated preprocessing tasks like data cleaning and imputation, generating an abstracted text file with metadata and statistical summaries, identifying outliers, conducting advanced analyses such as RFM and customer behavior clustering, converting data into embeddings using generative AI, and providing precise insights and strategic recommendations through a question-answering chatbox for informed decision-making.\n"
     ]
    }
   ],
   "source": [
    "#Using filters for specific page retrival\n",
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {'key': 'page_label', 'value': '3'} #based on the pageno retrival\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"What is 7th Sense\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '3', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n"
     ]
    }
   ],
   "source": [
    "for x in response.source_nodes:\n",
    "    print(x.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def vector_query(\n",
    "    query: str, \n",
    "    page_numbers: List[str]\n",
    ") -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "    \n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
    "        over all pages. Otherwise, filter by the set of specified pages.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = [\n",
    "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
    "    ]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "    \n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"summary\", \"page_numbers\": [\"2\"]}\n",
      "=== Function Output ===\n",
      "The papers discussed in the context cover a range of topics from retail sales forecasting to anomaly detection, customer segmentation, automated fashion analysis, and the intersection of large language models (LLMs) with data retrieval. Each paper contributes uniquely to the fields of retail analytics, fashion report generation, and data analysis, emphasizing the importance of advanced analytics and artificial intelligence in revolutionizing industries. The studies explore different methodologies and models, such as Random Forest Regression for sales forecasting, the RFM model for customer segmentation, GPT-FAR system for automated fashion analysis, and Retrieval-Augmented Generation (RAG) for enhancing LLM capabilities. Additionally, the research delves into the potential of LLMs like GPT-4 in data analysis tasks and raises questions about the role of traditional machine learning models in comparison to advanced language models.\n",
      "The papers discussed in the context cover a range of topics from retail sales forecasting to anomaly detection, customer segmentation, automated fashion analysis, and the intersection of large language models (LLMs) with data retrieval. Each paper contributes uniquely to the fields of retail analytics, fashion report generation, and data analysis, emphasizing the importance of advanced analytics and artificial intelligence in revolutionizing industries. The studies explore different methodologies and models, such as Random Forest Regression for sales forecasting, the RFM model for customer segmentation, GPT-FAR system for automated fashion analysis, and Retrieval-Augmented Generation (RAG) for enhancing LLM capabilities. Additionally, the research delves into the potential of LLMs like GPT-4 in data analysis tasks and raises questions about the role of traditional machine learning models in comparison to advanced language models.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-4o-mini', temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool],\n",
    "    \"Tell me the summary of page numbers 2, 3, 4\",\n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '2', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Summary Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of the paper\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"page 8\"}\n",
      "=== Function Output ===\n",
      "Page 8 of the document is not provided in the context information.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"give the summary of page 8?\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '1', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '2', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '2', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '3', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '4', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '5', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '6', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n",
      "{'page_label': '7', 'file_name': 'The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_path': '../src/The_7th_Sense_For_Data-Driven_Decision_Mastery_Paper_V2.pdf', 'file_type': 'application/pdf', 'file_size': 682557, 'creation_date': '2024-11-05', 'last_modified_date': '2024-10-30'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected at least one tool call, but got 0 tool calls.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_and_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvector_query_tool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgive is a summary of the paper?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/generativeai/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/miniforge3/envs/generativeai/lib/python3.11/site-packages/llama_index/core/llms/function_calling.py:190\u001b[0m, in \u001b[0;36mFunctionCallingLLM.predict_and_call\u001b[0;34m(self, tools, user_msg, chat_history, verbose, allow_parallel_tool_calls, error_on_no_tool_call, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict_and_call(\n\u001b[1;32m    175\u001b[0m         tools,\n\u001b[1;32m    176\u001b[0m         user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    182\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_with_tools(\n\u001b[1;32m    183\u001b[0m     tools,\n\u001b[1;32m    184\u001b[0m     user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    189\u001b[0m )\n\u001b[0;32m--> 190\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tool_calls_from_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_no_tool_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_no_tool_call\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m tool_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    194\u001b[0m     call_tool_with_selection(tool_call, tools, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tool_call \u001b[38;5;129;01min\u001b[39;00m tool_calls\n\u001b[1;32m    196\u001b[0m ]\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_parallel_tool_calls:\n",
      "File \u001b[0;32m~/miniforge3/envs/generativeai/lib/python3.11/site-packages/llama_index/llms/openai/base.py:894\u001b[0m, in \u001b[0;36mOpenAI.get_tool_calls_from_response\u001b[0;34m(self, response, error_on_no_tool_call, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tool_calls) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_on_no_tool_call:\n\u001b[0;32m--> 894\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    895\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least one tool call, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tool_calls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tool calls.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[0;31mValueError\u001b[0m: Expected at least one tool call, but got 0 tool calls."
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-4o-mini', temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"give is a summary of the paper?\", \n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generativeai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
